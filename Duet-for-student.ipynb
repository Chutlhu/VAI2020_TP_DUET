{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLIND SOURCE SEPARATION WITH DUET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical Exercise\n",
    "\n",
    "In this IPython notebook, we will implement DUET algorithm to perform speech source separation.\n",
    "In particolar, we will learn how to:\n",
    "    1. import audio and listen to it in python\n",
    "    2. perform a Short Time Fourier Transform and visualize its results as a Spectrogram\n",
    "    3. implement a naive version of the DUET algorthim (using only the phase information)\n",
    "    \n",
    "### References\n",
    "- _Rickard, Scott. “The DUET blind source separation algorithm.” Blind Speech Separation. Springer Netherlands, 2007._   \n",
    "- _Yilmaz, Ozgur, and Scott Rickard. “Blind separation of speech mixtures via time-frequency masking.” Signal Processing, IEEE transactions, 2004._\n",
    "\n",
    "Let's begin by importing the necessary libraries all of which can be installed with pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import find_peaks              # for peak-picking\n",
    "from mir_eval.separation import bss_eval_images  # for evaluation\n",
    "\n",
    "import soundfile as sf # to load audio files\n",
    "import stft # to perform stft\n",
    "\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some hyperparametes and fs-path\n",
    "Here some paths to the data folder and some hypersparameter.\n",
    "\n",
    "In this tutorial, we will do some _inform_ our source separation, that is, we use some a-priori knowledge.  \n",
    "In particular we know how many sound-sources/speaker we want to separate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some environmental parameter.\n",
    "dir_data = \"./data/\" \n",
    "dir_mix = dir_data + \"mixtures/\"    # path to the mixtures\n",
    "dir_gt = dir_data + \"ground_truth/\" # path to the clean sound sources\n",
    "fig_size = (10, 5)\n",
    "\n",
    "# analysis parameters\n",
    "wavefile = \"3speech_2chan.wav\"  # file to be analysed\n",
    "n_src = 2 # number of sound sources\n",
    "\n",
    "tw = 64 # [ms] STFT analysis window - it a typical parameter used in litterature\n",
    "ov = 50 # [%]  STFT window overlap  - it a typical parameter used in litterature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sound in Python\n",
    "Let's load the mixture signal, that is the signal recorded at the microphone.  \n",
    "... and listen to it with '''IPython.display.Audio'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load the mixture\n",
    "# TODO.\n",
    "#  - use the function in read of soundfile to import the file wav\n",
    "#  - check the dimension of the matrix (Samples x Channels)\n",
    "#  - use IPython.display.Audio to listen to one channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our hears are satisfied, let s plot the signals so that our eyes can enjoy as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Plot the mixture\n",
    "\n",
    "# TODO 1) plot the waveforms (all the channels)\n",
    "\n",
    "# plt.plot(......)\n",
    "# plt.legend(['channel 1', 'channel 2'])\n",
    "# plt.xlabel('Time [s]')\n",
    "# plt.ylabel('Amplitude')\n",
    "# plt.axes().set_aspect('auto')\n",
    "# plt.show()\n",
    "\n",
    "# TODO 2) change the axis to diplay the waveforms as fuction of time [seconds]\n",
    "\n",
    "# time_support = ???????\n",
    "# plt.plot(?????????)\n",
    "# plt.legend(['channel 1', 'channel 2'])\n",
    "# plt.xlabel('Time [s]')\n",
    "# plt.ylabel('Amplitude')\n",
    "# plt.axes().set_aspect('auto')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STFT reprensentation\n",
    "Most of the approaches in the litterature work in the Short Time Fourier Transform (STFT) domain.  \n",
    "DUET does the same. So we need to compute the stft of observed signal.\n",
    "\n",
    "### Reference\n",
    "https://en.wikipedia.org/wiki/Short-time_Fourier_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Go to STFT domain\n",
    "# TODO. Use:\n",
    "\n",
    "# TODO 1) stft(signal, frameSize, hopSize), frameSize in bin, hopSize in bins\n",
    "\n",
    "# nfft = int(???????????)\n",
    "# hop  = int(???????????)\n",
    "# print(nfft, hop)\n",
    "\n",
    "# MIX = stft.stft(???????????)\n",
    "# MIC1 = MIX[:,:,0]\n",
    "# MIC2 = MIX[:,:,1]\n",
    "# print(MIC1.shape)\n",
    "\n",
    "#  TODO 2) display the spectrogram\n",
    "\n",
    "# def plot_spectrogram(x):  \n",
    "#     #spectrogram = ???\n",
    "#     plt.imshow(spectrogram)\n",
    "#     plt.axes().set_aspect('auto')\n",
    "#     plt.xlabel('time frames')\n",
    "#     plt.ylabel('frequency bins')\n",
    "#     plt.colorbar()\n",
    "#     plt.show()\n",
    "\n",
    "plot_spectrogram(MIC1)  \n",
    "plot_spectrogram(MIC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Compute log-ratio of spectrograms\n",
    "# TODO.\n",
    "#    - compute the log ratio:\n",
    "#      - compute the log magnitude of the ratio (ILD)\n",
    "#      - compute the angle of the of the ratio (IPD)\n",
    "#      (hint check how to compute mag and of complex numbers)\n",
    "#    - display the resuls (hint: similar to plot_spectrogram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BLIND SOURCE SEPARATION WITH DUET\n",
    "\n",
    "In this part of the tutorial you are going to implement a vanilla version of the DUET algorithm.  \n",
    "The original algorithm estract both phase and magnitude information and cluster the peaks in a 3D space:  \n",
    "   (Delays/Phase x Amplitude/Magnitude x Histogram peaks)\n",
    "   \n",
    "Here we are going to use only the _magnitude_ information.\n",
    "\n",
    "### Bonus exercise\n",
    "Implement the full DUET algorithm with both phase and magnitude information.\n",
    "\n",
    "### References\n",
    "\n",
    "- _Rickard, Scott. “The DUET blind source separation algorithm.” Blind Speech Separation. Springer Netherlands, 2007._\n",
    "- _Yilmaz, Ozgur, and Scott Rickard. “Blind separation of speech mixtures via time-frequency masking.” Signal Processing, IEEE transactions, 2004._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 4) Compute histogram of ratios\n",
    "# TODO. Use:\n",
    "#   - np.histogram to compute the densities and the weights, you can use 200 bins\n",
    "#   - normalize the bins\n",
    "#   - plot the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 5) Extract peaks of the histogram\n",
    "# TODO.\n",
    "#   - do peak picking. How many? Do we know? (hint: check find_peaks in scypy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 6) Plot histogram and peaks\n",
    "# TODO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 7) Compute Masks\n",
    "# TODO.\n",
    "#    - for every time-frequency point, cluster it: decide to which mask it belongs \n",
    "#      using the information of the peaks and the wegths.\n",
    "#       - we have K masks as the number of sources/peaks.\n",
    "#    - plot the binary mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 8) Apply masks \n",
    "# TODO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 9) Save sounds\n",
    "# TODO. Use:\n",
    "#  - istft\n",
    "#  - wavwrite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATION\n",
    "Now it is time to evaluate our separation. It is common to use the MBSS_EVAL metrics (see References below).  \n",
    "Sound Mixture have:\n",
    "- target _sources_ of interests\n",
    "- _interferences_ (cross-talk)\n",
    "- _noise_ (reverberation or measuremets)  \n",
    "moreover, our algo can add spurious sounds, we call these sounds _artifacs_.\n",
    "\n",
    "This (originally matlab) toolboIx aim to quantify this _error_ with the following metrics:\n",
    "- SIR: Signal to Intereference ratio (estimated source vs. non-origin sources)\n",
    "- SAR: Signal to Artifact ratio (estimated source vs. artifacts)\n",
    "- SNR: Signal to Noise ratio    (estimated source vs. origin source)\n",
    "- SDR: Signal to Distortion ratio: an accumulating general metrics\n",
    "- (ISR: Image to Spatial Distortion ratios)\n",
    "\n",
    "In python we can use the module mir_eval (Music Information Retrieval evaluation). We just need to input our prediction and the ground-truth.\n",
    "\n",
    "### References\n",
    "- _http://craffel.github.io/mir_eval/ _\n",
    "- _http://bass-db.gforge.inria.fr/bss_eval/: A toolbox for performance measurement in (blind) source separation_\n",
    "- _E. Vincent, R. Gribonval and C. Févotte, Performance measurement in blind audio source separation, IEEE Trans. Audio, Speech and Language Processing, 14(4), pp 1462-1469, 2006._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 10) Evaluate method - load/create the ground-truth:\n",
    "# TODO. Use:\n",
    "#  - ground_truth sounds\n",
    "#  - plot the ground truth mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 10) Evaluate method:\n",
    "# TODO. Use:\n",
    "#  - create two matrix Channel x Samples x Images, one stacking the gt sources, the other staking\n",
    "#    estimated sounds\n",
    "#  - bss_eval_images in mir_eval module"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
